{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telephone Subscription Prediction.\n",
    "\n",
    "This project will requires you to\n",
    "\n",
    "* analyze and clean data\n",
    "* identify predictive features and test hypothesis\n",
    "* choose between fundamental classification metrics\n",
    "* fit and fine-tune a logreg and xgboost model for prediction\n",
    "\n",
    "The task we are solving for is to predict if customer will subscribe to telephone service or not.\n",
    "\n",
    "The project is organized in several Modules. Each Module has a set of tasks for you to complete. <br>\n",
    "Please make sure to complete one task before moving onto the next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are package to be loaded\n",
    "# Do not alter\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "\n",
    "# TODO this is path to data folder, please remove if not required\n",
    "data_folder = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Analyze and Clean Data\n",
    "\n",
    "You start your data project by analyzing the data <br> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(data_folder + \"train.csv\")\n",
    "feats = list(train_df.columns[:-1])\n",
    "label = train_df.columns[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - Understand the Data\n",
    "\n",
    "For this task, simply have a look at the data. Load the training data and take a look at the values for the following features\n",
    "* Months since Last Donation\n",
    "* Number of Dontations\n",
    "* Total Volume Donated\n",
    "* Month since First Donation <br/> <br/>\n",
    "\n",
    "and labels - Made Dontation in March 2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Solution below, please remove \n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Solution below, please remove\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['age','balance','duration']\n",
    "cat_cols = ['job','marital','education','default','housing','loan','contact','month','day','campaign','pdays','previous','poutcome']\n",
    "label = 'subscribed'\n",
    "\n",
    "for col in cat_cols:\n",
    "    print(train_df[col].value_counts())\n",
    "\n",
    "# TODO: Understand features  - 'campaign','pdays','previous','poutcome' (treating as numerical for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Remove any duplicate rows\n",
    "\n",
    "`Ask ChatGPT! : How does duplicate data impact performance of a Logistic Regression model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(df: pd.DataFrame) -> pd.DataFrame :\n",
    "    '''\n",
    "    Complete this function to return a de-duplicated dataframe\n",
    "    '''\n",
    "    \n",
    "    # TODO: remove the rest of code in this function\n",
    "    df = df.drop_duplicates()\n",
    "    return df\n",
    "\n",
    "\n",
    "# Do not change this code\n",
    "row_count = remove_duplicates(train_df).shape[0]\n",
    "print(row_count)\n",
    "remove_duplicates(train_df.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 - Fill Missing Values\n",
    "\n",
    "Fill any missing values in the data with column means (even if there are no missing value, this function will execute)\n",
    "\n",
    "`Ask ChatGPT! : How does missing values impact performance of a Logistic Regression model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_col_miss = {}\n",
    "def fill_missing_value(df: pd.DataFrame, train=False) -> pd.DataFrame:\n",
    "    '''\n",
    "    Complete this function to fill missing (if there are)\n",
    "    with the mean value of the column for numerical features, \n",
    "    and model for categorical features\n",
    "\n",
    "    `train_col_mean` is a dictionary where keys are features\n",
    "    and values are mean of field\n",
    "\n",
    "    Hint: Use feats to iterate through columns\n",
    "    '''\n",
    "\n",
    "    # TODO: Solution below, please remove\n",
    "\n",
    "    for col in num_cols:\n",
    "        if train:\n",
    "            train_col_miss[col] = df[col].mean()\n",
    "        \n",
    "        df[col] = df[col].fillna(train_col_miss[col])\n",
    "\n",
    "    for col in cat_cols:\n",
    "        if train:\n",
    "            train_col_miss[col] = df[col].mode()\n",
    "\n",
    "        df[col] = df[col].fillna(train_col_miss[col])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Do not change this line of code\n",
    "fill_missing_value(train_df.copy(), train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 - Identify outliers\n",
    "\n",
    "Compelete the below function to clip outlier using `Tukey Outlier method`. Replace the outlier with mean values.\n",
    "\n",
    "`Ask ChatGPT! : How does outlier impact performance of a Logistic Regression Model`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_col_bounds = {}\n",
    "def clip_outliers(df: pd.DataFrame, train=False) -> pd.DataFrame:\n",
    "    '''\n",
    "    Complete this function to get lower, upper bounds of each col\n",
    "    Replace low and high with mean values\n",
    "\n",
    "    `train_col_bounds` is a dictionary where key are features\n",
    "    and values are tuple (x,y) x being lower bound and y being higher bound\n",
    "\n",
    "    Hint: Use feats to iterate through columns\n",
    "    '''\n",
    "\n",
    "    # TODO: solution below, please remove\n",
    "    for col in num_cols:\n",
    "        if train:\n",
    "            p25, p75 = df[col].quantile([.25,.75])\n",
    "            iqr = p75 - p25\n",
    "            train_col_bounds[col] = (p25 - 1.5 * iqr, p75 + 1.5 * iqr)\n",
    "\n",
    "        df[col] = df[col].apply(lambda x: train_col_miss[col] if (x < train_col_bounds[col][0] or x >  train_col_bounds[col][0]) else x)\n",
    "    print(train_col_bounds)\n",
    "\n",
    "\n",
    "# Do not change this code\n",
    "clip_outliers(train_df.copy(), train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5 -  Identify imbalance\n",
    "\n",
    "Complete this function to return the percentage of 0 labels in the data\n",
    "Knowing this - what should you do when you build the model?\n",
    "\n",
    "`Ask ChatGPT! : How does imbalance impact performance of a Logistic Regression Model`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_imbalance(df: pd.DataFrame) -> float:\n",
    "    '''\n",
    "    Copmlete this function to return the percentage of 0 labels in the data\n",
    "    '''\n",
    "\n",
    "    # TODO: Solution below, please remove\n",
    "    return df[label].value_counts(normalize=True)[1] * 100\n",
    "\n",
    "test_imbalance(train_df.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "First lets work on encoding the categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6 - Encoding categorical variables \n",
    "Use OneHotEncoder to encode categorical values\n",
    "\n",
    "`Ask ChatGPT: What are the different types of categorical encoding and advantages of each`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cat_enc = None\n",
    "def encode_cat(df: pd.DataFrame, train=False):\n",
    "    '''\n",
    "    Use 'OneHotEncoder' to encode categorical values\n",
    "    Remember that the encoder must be saved in `cat_enc` \n",
    "    so that it can used on a test set later\n",
    "\n",
    "    '''\n",
    "\n",
    "    global cat_enc\n",
    "\n",
    "    # TODO: Solution below, remove\n",
    "    if train:\n",
    "        le = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "        le = le.fit(df[cat_cols])\n",
    "        cat_enc = le\n",
    "\n",
    "    le = cat_enc\n",
    "    encoded_df = le.transform(df[cat_cols])\n",
    "\n",
    "    encoded_df = pd.DataFrame(encoded_df, columns=le.get_feature_names_out(cat_cols))\n",
    "\n",
    "    df = pd.concat([df.drop(columns=cat_cols), encoded_df], axis=1)\n",
    "\n",
    "    if train:\n",
    "        df[label] = df[label].apply(lambda x: 0 if x == 'no' else 1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Do not change this code\n",
    "train_df = pd.read_csv(data_folder + \"train.csv\")\n",
    "train_df = encode_cat(train_df.copy(), train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[label].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a feature to be useful it must have some predictive power. <br>\n",
    "In classification problem the label is a `categorical` value  and the feature we have all 'continuous' valued.\n",
    "\n",
    "In this case the statisitical test we use to test if a feature is useful or not is called - `Student's t-test.` <br>\n",
    "This is test use if you have only two values in `categorical` label and `continuous` valued features. \n",
    "\n",
    "Some of the other tests you might need to know are - <br>\n",
    "https://medium.com/towards-data-science/every-statistical-test-to-check-feature-dependence-773a21cd6722\n",
    "\n",
    "\n",
    "Now, one of the assumptions of the Student's t-test is - `Normality` i.e. the feature value should follow a normal distribution for each value of the label. <br>\n",
    "Now the test is robust enough that if we have more that 30 samples the results still hold, but lets still have a look at the features and see if any of them are normally distributed. <br>\n",
    "\n",
    "## Task 7 - Feature Distribution\n",
    "Understand feature distributions - plot histogram of feature values for each class. This will help you understand if the feature values overlap or not <br>\n",
    "\n",
    "`Ask ChatGPT: How does feature value overlap influence Logigisic Regression model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Solution below, please remove\n",
    "feats = num_cols\n",
    "print(num_cols)\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 6))\n",
    "\n",
    "for i, feat in enumerate(feats):\n",
    "    row = i // 3\n",
    "    col = i % 3\n",
    "    train_df[train_df[label]==0][feat].hist(ax=axes[row, col])\n",
    "    train_df[train_df[label]==1][feat].hist(ax=axes[row+1, col])\n",
    "    axes[row, col].set_title(feat)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7.a - Feature Correlations\n",
    "\n",
    "Since all features are continuous you can use pandas default correction (Pearson Corr) \n",
    "Knowing this - what should you do when you build the model?\n",
    "\n",
    "`Ask ChatGPT! : How do correlated feature impact performance of a Logistic Regression Model.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_corr_num(df: pd.DataFrame) -> None:\n",
    "    '''\n",
    "    Complete the function to calculate all pairwise correlation\n",
    "    From the output Identify the pair of features that are highly correlated.\n",
    "    '''\n",
    "    \n",
    "    # TODO: Solution below, please remove\n",
    "    return df[num_cols].corr()\n",
    "\n",
    "\n",
    "# Do not change this code\n",
    "calc_corr_num(train_df[feats])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7.b - Feature Correlation\n",
    "\n",
    "Check if any pair of categorical features are correlated. Since all features are categorical you can use Chi-Square\n",
    "\n",
    "`Ask ChatGPT: What is the downside of using p-values when doing multiple hypothesis testing?` <br>\n",
    "\n",
    "`Ask ChatGPT: Is Chi-square reliable when fields have high cardinality`. Based on this answer we will skip testing for relevance of categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def calc_corr_cat(df: pd.DataFrame) -> None:\n",
    "    '''\n",
    "    Complete the function to calculate all pairwise correlation\n",
    "    From the output Identify the pair of features that are highly correlated.\n",
    "    '''\n",
    "\n",
    "    # TODO: Solution below, please remove\n",
    "    for feat1 in cat_cols[:-1]:\n",
    "        for feat2 in cat_cols[1:]:\n",
    "\n",
    "            # Create a contingency table\n",
    "            contingency_table = pd.crosstab(df[feat1], df[feat2])\n",
    "\n",
    "            # Perform the Chi-Square test\n",
    "            chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "            \n",
    "            print(f\"{feat1} {feat2} Chi-Square value: {chi2} P-value: {p_value}\")\n",
    "\n",
    "\n",
    "# Do not change this code\n",
    "temp_df = pd.read_csv(data_folder + 'train.csv')\n",
    "calc_corr_cat(temp_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Task 7.c\n",
    "# # Check if pair of categorical - numeric features are correlated\n",
    "# # For this you can use the F-test\n",
    "\n",
    "# def calc_corr_cat_num(df: pd.DataFrame) -> None:\n",
    "#     '''\n",
    "#     Complete the function to calculate all pairwise correlation\n",
    "#     From the output Identify the pair of features that are highly correlated.\n",
    "#     '''\n",
    "    \n",
    "#     # TODO: Solution below, please remove\n",
    "#     for feat1 in num_cols:\n",
    "#         for feat2 in cat_cols:\n",
    "#             groups = df.groupby(feat2)[feat1].apply(list)\n",
    "#             f_statistic, p_value = f_oneway(*groups)\n",
    "\n",
    "#             print(feat1, feat2, f_statistic, p_value)\n",
    "\n",
    "\n",
    "# # Do not change this code\n",
    "# calc_corr_cat_num(train_df)\n",
    "\n",
    "# # Ask ChatGPT: Is F-test reliable when fields have high cardinality?\n",
    "# # Based on this should we remove any feature that high association?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8\n",
    "\n",
    "Check which of the numeric feature are predictive (i.e. will a donor donate blood). For this you can used a specific statistical test called 'Welch's t-test'. Which of the feature are not predictive assuming significance alpha = 0.01\n",
    "\n",
    "`Ask ChatGPT:  What is welch's t-test, and t-test - how does it help determing important features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_student_ttest(df, col) -> tuple[str, float]:\n",
    "    '''\n",
    "    Write a function to return p-values from the Welch's t-test\n",
    "    for feature passed into the function\n",
    "    '''\n",
    "\n",
    "    # TODO: Solution below, please remove\n",
    "    t_stat, p_val = stats.ttest_ind(df[df[label]==0][col], df[df[label]==1][col], \n",
    "                                        equal_var=False)  # Welch's t-test\n",
    "    \n",
    "    print(col, t_stat, p_val)\n",
    "\n",
    "\n",
    "for feat in num_cols:\n",
    "    run_student_ttest(train_df, feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Task 8.b\n",
    "# # Check which of the categorical feature are predictive (i.e. will a donor donate blood)\n",
    "# # For this you can used a specific statistical test called 'Chi-sqaure test'\n",
    "# # Which of the feature are not predictive assuming significance alpha = 0.01\n",
    "\n",
    "# def run_chi_test(df, col) -> tuple[str, float]:\n",
    "#     '''\n",
    "#     Write a function to return p-values from the Welch's t-test\n",
    "#     for feature passed into the function\n",
    "#     '''\n",
    "\n",
    "#     # Create a contingency table\n",
    "#     contingency_table = pd.crosstab(df[col], df[label])\n",
    "\n",
    "#     # Perform the Chi-Square test\n",
    "#     chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "    \n",
    "#     print(f\"{col} {label} Chi-Square value: {chi2} P-value: {p_value}\")\n",
    "\n",
    "# for feat in cat_cols:\n",
    "#     run_chi_test(train_df, feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Classification Metrics\n",
    "\n",
    "The most common classification metrics are - \n",
    "* Accuraccy\n",
    "* Precision\n",
    "* Recall\n",
    "* F1-Score\n",
    "Let's Ask ChatGPT what there are - <br>\n",
    "\n",
    "\n",
    "Now having analyzed the data (from Task 1), choose the best metrics for your task. <br>\n",
    "<br>\n",
    "\n",
    "Assume you got the following information from business - \n",
    "* If you prediction someone is going to subscribe, but they dont - this is huge concern. You want to reduce such `false positives` as much as possible.\n",
    "* If you predict someone is not going to subscribe, and they do - it is ok.\n",
    "\n",
    "Knowing the above - decide which metric to use. <br>\n",
    "Irrespective of what you use evaluate performance using F1 as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 11\n",
    "\n",
    "Now having analyzed the data (from Task 1), choose the best metrics for your task. <br>\n",
    "<br>\n",
    "\n",
    "Assume you got the following information from business - \n",
    "* If you prediction someone is going to donate, but they dont - this is huge concern. You want to reduce such `false positives` as much as possible.\n",
    "* If you predict someone is not going to donate, and they do come - it is ok. The blood donation camp can manage.\n",
    "\n",
    "Knowing the above - decide which metric to use. <br>\n",
    "Irrespective of what you use evaluate performance using F1 as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calc_perf(y_act: list, y_pred: list) -> float:\n",
    "    '''\n",
    "    Compelete this function to calculate the metric\n",
    "    you have chosen\n",
    "    '''\n",
    "\n",
    "    # TODO: Solution below, pleas remove\n",
    "    val = precision_score(y_act, y_pred)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "Now, finally we can start training the model. When training an ML model its important to have three datasets\n",
    "* Train dataset - which you use to train the model and learn parameter\n",
    "* Validation dataset - the dataset to use to figure out which parameter are the best\n",
    "* Test dataset - the hidden dataset, that you DO NOT look at. Its only use to estimate the performance in future unseen datasets.\n",
    "\n",
    "## Task 12 - Preproces the train data to create traininig and validation data\n",
    "\n",
    "Lets start by creating these datasets - \n",
    "1. Load the train dataset \n",
    "2. ONLY run the de-duplication function on train set (lets see what performance we get without outlier removal and feature engineering)\n",
    "3. Split train dataset 80:20 to creatin a new train dataset and validation set\n",
    "2. Load the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(df: pd.DataFrame) -> tuple[np.array, np.array, np. array, np.array]:\n",
    "    '''\n",
    "    Remove duplicate data from train file alone \n",
    "    Encode the categorical values\n",
    "    Split train file data into train and valid set (keep in mind what we about imbalance learned in Task 5)\n",
    "        Hint use: train_test_split (set seed to 100), and use the `stratify` field\n",
    "        Ask ChatGPT: Why is it important to stratify when creating training and validation sets for imbalanced datasets\n",
    "    \n",
    "    Return np. arrays for train features, train labels, valid features, valid labels, feature names\n",
    "\n",
    "    '''\n",
    "\n",
    "    # TODO: Solution below, pleas remove\n",
    "    df = remove_duplicates(df)\n",
    "    df = encode_cat(df, train=True)\n",
    "\n",
    "    feats = list(df.columns)\n",
    "    feats.remove(label)\n",
    "    feats.remove('ID')\n",
    "\n",
    "    X = df[feats].values\n",
    "    y = df[label].values\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, \n",
    "                                                          stratify=y, random_state=100)\n",
    "\n",
    "    return X_train, y_train, X_valid, y_valid, feats\n",
    "\n",
    "\n",
    "# Do not change this\n",
    "X_train, y_train, X_valid, y_valid, feats = create_dataset(pd.read_csv(data_folder + 'train.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 13 - Build Model\n",
    "Train a basline Logisitc Regression model with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_base(X_train: np.array, y_train: np.array) -> LogisticRegression:\n",
    "    '''\n",
    "    Complete this function to\n",
    "    Train a baseline LogisticRegression Model with default parameter\n",
    "    Use random_state = 100 to keep results consistent\n",
    "    '''\n",
    "\n",
    "    # TODO: Solution below, please remove\n",
    "    model = LogisticRegression(random_state=100)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Do not change this\n",
    "model = train_base(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_train)\n",
    "print(\"Train Performance\")\n",
    "print(\"Selected Metric: \", calc_perf(y_train, pred), \"F1-Score: \", f1_score(y_train, pred))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "pred = model.predict(X_valid)\n",
    "print(\"Validation Performance\")\n",
    "print(\"Selected Metric: \", calc_perf(y_valid, pred),\"F1-Score: \", f1_score(y_valid, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving baseline Model and Analyzing Design Choices\n",
    "\n",
    "## Task 14 - Fix imbalance to improve performance\n",
    "\n",
    "Use sampling to balance the number positive and negative samples in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebalance_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Write a function to \n",
    "    (a) remove duplicate rows in data\n",
    "    (b) balance the number of positive and negative samples in train_data\n",
    "    Hint: Use downsampling, use random_state = 100\n",
    "    Hint: Dont forget to reset index after creating a new dataframe\n",
    "\n",
    "    Return balance dataframe\n",
    "    '''\n",
    "\n",
    "    # TODO: Solution below, please remove\n",
    "    df = remove_duplicates(df)\n",
    "\n",
    "    pos_df = df[df[label] == 'yes']\n",
    "    neg_df = df[df[label] == 'no']\n",
    "\n",
    "    df = pd.concat([neg_df.sample(frac=0.4, random_state=100), pos_df]).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Do not change the following code\n",
    "# load the data\n",
    "train_df = pd.read_csv(data_folder + 'train.csv')\n",
    "print(train_df.shape, train_df[label].value_counts(normalize=True))\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# balance the data\n",
    "train_df = rebalance_df(train_df)\n",
    "print(\"Balanced\", train_df.shape, train_df[label].value_counts(normalize=True))\n",
    "\n",
    "# check the performance with rebalance dataset\n",
    "print(\"\\n\\n\")\n",
    "X_train, y_train, X_valid, y_valid, feats = create_dataset(train_df)\n",
    "model = train_base(X_train, y_train)\n",
    "print(X_train.shape)\n",
    "\n",
    "pred = model.predict(X_train)\n",
    "print(\"Train Performance\")\n",
    "print(\"Selected Metric: \", calc_perf(y_train, pred), \"F1-Score: \", f1_score(y_train, pred))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "pred = model.predict(X_valid)\n",
    "print(\"Validation Performance\")\n",
    "print(\"Selected Metric: \", calc_perf(y_valid, pred),\"F1-Score: \", f1_score(y_valid, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 15 - Improve model using Class Imbalance\n",
    "\n",
    "Another way to combat data imbalance is configuring class weights in the Logistic Regression model <br>\n",
    "\n",
    "`Ask ChatGPT: Why does one of the methods perform better than the other`\n",
    "Hint: It could be related to the how the feature distribution for both class overlap as seen in Task 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tune_model(X_train: np.array, y_train: np.array):\n",
    "    '''\n",
    "    Write the function to train a Logistic Regression model\n",
    "    and use `class_weight` parameter\n",
    "    Use random_state = 100 to keep results consistent\n",
    "    '''\n",
    "\n",
    "    # TODO: Solution below, please remove code\n",
    "    model = LogisticRegression(class_weight={0:0.25, 1:0.75 }, random_state=100)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# do no change the following code\n",
    "train_df = pd.read_csv(data_folder + 'train.csv')\n",
    "X_train, y_train, X_valid, y_valid, feats = create_dataset(train_df)\n",
    "\n",
    "model = train_tune_model(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_train)\n",
    "print(\"Train Performance\")\n",
    "print(\"Selected Metric: \", calc_perf(y_train, pred), \"F1-Score: \", f1_score(y_train, pred))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "pred = model.predict(X_valid)\n",
    "print(\"Validation Performance\")\n",
    "print(\"Selected Metric: \", calc_perf(y_valid, pred),\"F1-Score: \", f1_score(y_valid, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Did the performance drop? If so, why? <br>\n",
    "When you add which feature back in is the performance coming back up? <br>\n",
    "\n",
    "Does it make sense that adding a feature that failed student t-test helped improve performance of Logistic Regression? <br>\n",
    "\n",
    "`Ask ChatGPT why this could happen (Hint it could be related to how features work together)`\n",
    "\n",
    "## Task 16 - Normalizing Features\n",
    "\n",
    "Normalize features to see how it impact perforamance for the Log.Reg model from the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tune_model(X_train: np.array, y_train: np.array, \n",
    "                     scaler):\n",
    "    '''\n",
    "    Complete this function to normalize features \n",
    "    X_train: is the train features values\n",
    "    y_train: is train labels\n",
    "    scaler: The scaler you have chosen\n",
    "\n",
    "    Bonus [Optional] Task : \n",
    "    Fine-tune the Logistic Regression Model.\n",
    "    Some of the parameters you may want to experiment with are - solver, penatly and C\n",
    "    '''\n",
    "\n",
    "    # Hint: Use StandardScaler to normalize features\n",
    "    # Ask ChatGPT what type of feature scaling is best for Logistic Regression and why\n",
    "\n",
    "    # TODO: Solution below, remove this code\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "    model = LogisticRegression(solver = 'liblinear', penalty='l1', C=0.5)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    return (model, scaler)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Do not change this code\n",
    "train_df = pd.read_csv(data_folder + \"train.csv\")\n",
    "train_df = rebalance_df(train_df)\n",
    "# train_df = drop_feature(train_df, cols = ['Total Volume Donated (c.c.)'])\n",
    "\n",
    "X_train, y_train, X_valid, y_valid, feats = create_dataset(train_df)\n",
    "model, scaler = train_tune_model(X_train, y_train, scaler)\n",
    "\n",
    "X_valid = scaler.transform(X_valid) # we use the same scaler you have used earlier\n",
    "pred = model.predict(X_valid)\n",
    "print(\"Validation Performance\")\n",
    "print(\"Selected Metric: \", calc_perf(y_valid, pred),\"F1-Score: \", f1_score(y_valid, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 17 - Model Interpretability\n",
    "\n",
    "Extract the coefficient from the model by completing this function\n",
    "\n",
    "`Ask ChatGPT: How do you interpret coeffcient of a Logistic Regression model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_coeff(model : LogisticRegression, feats: list):\n",
    "    '''\n",
    "    Complete this function to print pair of values\n",
    "    (feature name, coeff value)\n",
    "    '''\n",
    "\n",
    "    # TODO: Remove this code\n",
    "    coeffs = list(model.coef_)[0]\n",
    "    print(coeffs)\n",
    "\n",
    "    for i in range(len(feats)):\n",
    "        print(feats[i], coeffs[i])\n",
    "    \n",
    "    print(\"Intercept\", model.intercept_)\n",
    "\n",
    "\n",
    "get_model_coeff(model, feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 18 -  Error Analysis\n",
    "This is crucial to identify what went wrong and how it could be improved. Use a confusion matrix to figure out if the model is making more false positive or false negative. <br>\n",
    "\n",
    "Identfiy if certain subset of data is more subsceptible to error (like certain jobs, durations etc).Based on the above insights figure out how the model could be improved. Think first - feature engineering, then improve Log.Reg fitting, and then experimenting with other models. \n",
    "\n",
    "**Do not jump to trying out other models directly, this is not standard industry practice**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = y_valid\n",
    "pred = model.predict(X_valid)\n",
    "\n",
    "# TODO: Remove code below\n",
    "tn, fp, fn, tp = confusion_matrix(actual, pred).ravel()\n",
    "print(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update predictions based on insights from error-analysis\n",
    "# TODO: FOR TESTING - SIMPLY CHECK IF PREDICTIONS ARE BETTER THAN THAT FROM TASK.18\n",
    "pred = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 19 - Model Experimentation\n",
    "Try-out other models, here we will be experimenting with RFClassifier. Its common in the industry to decide to spend 2-3 days on model experimentation. During this time you can experiment with as many models, fine-tuning techniques as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remove code below\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "train_df = pd.read_csv(data_folder + \"train.csv\")\n",
    "train_df = rebalance_df(train_df)\n",
    "\n",
    "X_train, y_train, X_valid, y_valid, feats = create_dataset(train_df)\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "pred = rf_classifier.predict(X_valid)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Validation Performance\")\n",
    "print(\"Selected Metric: \", calc_perf(y_valid, pred),\"F1-Score: \", f1_score(y_valid, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 20 - Final Prediction\n",
    "Finally apply all the transformation you deem best on the data and the best model you found to get prediction on test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_df = pd.read_csv(data_folder + 'test.csv')\n",
    "\n",
    "# TODO: Remove Solution below\n",
    "test_df = encode_cat(test_df, train=False)\n",
    "test_df = test_df.drop(columns=['ID'])\n",
    "test_arr = scaler.transform(test_df.values)\n",
    "pred = model.predict(test_arr)\n",
    "print(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
