{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telephone Subscription Prediction.\n",
    "\n",
    "This project will requires you to\n",
    "\n",
    "* analyze and clean data\n",
    "* identify predictive features and test hypothesis\n",
    "* choose between fundamental classification metrics\n",
    "* fit and fine-tune a logreg and xgboost model for prediction\n",
    "\n",
    "The task we are solving for is to predict if customer will subscribe to telephone service or not.\n",
    "\n",
    "The project is organized in several Modules. Each Module has a set of tasks for you to complete. <br>\n",
    "Please make sure to complete one task before moving onto the next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are package to be loaded\n",
    "# Do not alter\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "\n",
    "# TODO this is path to data folder, please remove if not required\n",
    "data_folder = \"telephonic_term/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Analyze and Clean Data\n",
    "\n",
    "You start your data project by analyzing the data <br> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(data_folder + \"train.csv\")\n",
    "feats = list(train_df.columns[:-1])\n",
    "label = train_df.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1\n",
    "# For this task, simply have a look at the data\n",
    "# Load the training data and take a look at feature values and answer these questions\n",
    "# - Is it a continous feature or categorical feature\n",
    "# - For continuous features - what are the range of values\n",
    "# - For categorical features - what are unique values possible\n",
    "\n",
    "# TODO: Solution below, please remove \n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Solution below, please remove\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['age','balance','duration']\n",
    "cat_cols = ['job','marital','education','default','housing','loan','contact','month','day','campaign','pdays','previous','poutcome']\n",
    "label = 'subscribed'\n",
    "\n",
    "for col in cat_cols:\n",
    "    print(train_df[col].value_counts())\n",
    "\n",
    "# TODO: Understand features  - 'campaign','pdays','previous','poutcome' (treating as numerical for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2\n",
    "# Remove any duplicate rows from the training data\n",
    "# Ask ChatGPT! : How does duplicate data impact performance of a Logistic Regression model\n",
    "\n",
    "def remove_duplicates(df: pd.DataFrame) -> pd.DataFrame :\n",
    "    '''\n",
    "    Complete this function to return a de-duplicated dataframe\n",
    "    '''\n",
    "    \n",
    "    # TODO: remove the rest of code in this function\n",
    "    df = df.drop_duplicates()\n",
    "    return df\n",
    "\n",
    "\n",
    "# Do not change this code\n",
    "row_count = remove_duplicates(train_df).shape[0]\n",
    "print(row_count)\n",
    "remove_duplicates(train_df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3\n",
    "# Fill any missing values in the data with column means (even if there are no missing value, this function will execute)\n",
    "# Ask ChatGPT! : How does missing values impact performance of a Logistic Regression model\n",
    "\n",
    "train_col_miss = {}\n",
    "def fill_missing_value(df: pd.DataFrame, train=False) -> pd.DataFrame:\n",
    "    '''\n",
    "    Complete this function to fill missing (if there are)\n",
    "    with the mean value of the column for numerical features, \n",
    "    and model for categorical features\n",
    "\n",
    "    `train_col_mean` is a dictionary where keys are features\n",
    "    and values are mean of field\n",
    "\n",
    "    Hint: Use feats to iterate through columns\n",
    "    '''\n",
    "\n",
    "    # TODO: Solution below, please remove\n",
    "\n",
    "    for col in num_cols:\n",
    "        if train:\n",
    "            train_col_miss[col] = df[col].mean()\n",
    "        \n",
    "        df[col] = df[col].fillna(train_col_miss[col])\n",
    "\n",
    "    for col in cat_cols:\n",
    "        if train:\n",
    "            train_col_miss[col] = df[col].mode()\n",
    "\n",
    "        df[col] = df[col].fillna(train_col_miss[col])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Do not change this line of code\n",
    "fill_missing_value(train_df.copy(), train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4\n",
    "# Identify if there are any outlier value in each of the features\n",
    "# Ask ChatGPT! : How does outlier impact performance of a Logistic Regression Model\n",
    "\n",
    "\n",
    "train_col_bounds = {}\n",
    "def clip_outliers(df: pd.DataFrame, train=False) -> pd.DataFrame:\n",
    "    '''\n",
    "    Complete this function to get lower, upper bounds of each col\n",
    "    Replace low and high with mean values\n",
    "\n",
    "    `train_col_bounds` is a dictionary where key are features\n",
    "    and values are tuple (x,y) x being lower bound and y being higher bound\n",
    "\n",
    "    Hint: Use feats to iterate through columns\n",
    "    '''\n",
    "\n",
    "    # TODO: solution below, please remove\n",
    "    for col in num_cols:\n",
    "        if train:\n",
    "            p25, p75 = df[col].quantile([.25,.75])\n",
    "            iqr = p75 - p25\n",
    "            train_col_bounds[col] = (p25 - 1.5 * iqr, p75 + 1.5 * iqr)\n",
    "\n",
    "        df[col] = df[col].apply(lambda x: train_col_miss[col] if (x < train_col_bounds[col][0] or x >  train_col_bounds[col][0]) else x)\n",
    "    print(train_col_bounds)\n",
    "\n",
    "\n",
    "# Do not change this code\n",
    "clip_outliers(train_df.copy(), train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5\n",
    "# Idetify amount of imbalance in data\n",
    "# Ask ChatGPT! : How does imbalance impact performance of a Logistic Regression Model\n",
    "# Knowing this - what should you do when you build the model?\n",
    "\n",
    "\n",
    "def test_imbalance(df: pd.DataFrame) -> float:\n",
    "    '''\n",
    "    Copmlete this function to return the percentage of 0 labels in the data\n",
    "    '''\n",
    "\n",
    "    # TODO: Solution below, please remove\n",
    "    return df[label].value_counts(normalize=True)[1] * 100\n",
    "\n",
    "test_imbalance(train_df.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "First lets work on encoding the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 6\n",
    "# Encoding categorical variables \n",
    "# Ask ChatGPT: What are the different types of categorical encoding and advantages of each\n",
    "\n",
    "cat_enc = {}\n",
    "def encode_cat(train_df: pd.DataFrame, train=False):\n",
    "    '''\n",
    "    Use 'LabelEncoder' to encode categorical values\n",
    "    The cat_enc dictionary can be use to store the encoders for each feature\n",
    "    This dictionary can then be use to transform test set\n",
    "\n",
    "    Also encode the label with no being 0, yes being 1\n",
    "    '''\n",
    "\n",
    "    # TODO: Solution below, remove\n",
    "\n",
    "    for col in cat_cols:\n",
    "\n",
    "        if train:\n",
    "            le = LabelEncoder()\n",
    "            le.fit(train_df[col])\n",
    "            cat_enc[col] = le\n",
    "\n",
    "        train_df[col] = le.transform(train_df[col])\n",
    "\n",
    "\n",
    "    train_df[label] = train_df[label].apply(lambda x: 0 if x == 'no' else 1)\n",
    "\n",
    "    return train_df\n",
    "\n",
    "\n",
    "# Do not change this code\n",
    "train_df = pd.read_csv(data_folder + \"train.csv\")\n",
    "train_df = encode_cat(train_df.copy(), train=True)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[label].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a feature to be useful it must have some predictive power. <br>\n",
    "In classification problem the label is a `categorical` value  and the feature we have all 'continuous' valued.\n",
    "\n",
    "In this case the statisitical test we use to test if a feature is useful or not is called - `Student's t-test.` <br>\n",
    "This is test use if you have only two values in `categorical` label and `continuous` valued features. \n",
    "\n",
    "Some of the other tests you might need to know are - <br>\n",
    "https://medium.com/towards-data-science/every-statistical-test-to-check-feature-dependence-773a21cd6722\n",
    "\n",
    "\n",
    "Now, one of the assumptions of the Student's t-test is - `Normality` i.e. the feature value should follow a normal distribution for each value of the label. <br>\n",
    "Now the test is robust enough that if we have more that 30 samples the results still hold, but lets still have a look at the features and see if any of them are normally distributed. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 7\n",
    "# Understand feature distributions - plot histogram of feature values for each class\n",
    "# This will help you understand if the feature values overlap or not\n",
    "# Ask ChatGPT: How does feature value overlap influence Logigisic Regression model\n",
    "\n",
    "\n",
    "# TODO: Solution below, please remove\n",
    "feats = num_cols\n",
    "print(num_cols)\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 6))\n",
    "\n",
    "for i, feat in enumerate(feats):\n",
    "    row = i // 3\n",
    "    col = i % 3\n",
    "    train_df[train_df[label]==0][feat].hist(ax=axes[row, col])\n",
    "    train_df[train_df[label]==1][feat].hist(ax=axes[row+1, col])\n",
    "    axes[row, col].set_title(feat)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 7.a\n",
    "# Check if any pair of numeric features are correlated\n",
    "# Since all features are continuous you can use pandas default correction (Pearson Corr) \n",
    "\n",
    "# Ask ChatGPT! : How do correlated feature impact performance of a Logistic Regression Model. \n",
    "# Knowing this - what should you do when you build the model?\n",
    "\n",
    "def calc_corr_num(df: pd.DataFrame) -> None:\n",
    "    '''\n",
    "    Complete the function to calculate all pairwise correlation\n",
    "    From the output Identify the pair of features that are highly correlated.\n",
    "    '''\n",
    "    \n",
    "    # TODO: Solution below, please remove\n",
    "    return df[num_cols].corr()\n",
    "\n",
    "\n",
    "# Do not change this code\n",
    "calc_corr_num(train_df[feats])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 7.b\n",
    "# Check if any pair of categorical features are correlated\n",
    "# Since all features are categorical you can use Chi-Square\n",
    "\n",
    "# Ask ChatGPT: What is the downside of using p-values when doing multiple hypothesis testing?\n",
    "\n",
    "def calc_corr_cat(df: pd.DataFrame) -> None:\n",
    "    '''\n",
    "    Complete the function to calculate all pairwise correlation\n",
    "    From the output Identify the pair of features that are highly correlated.\n",
    "    '''\n",
    "\n",
    "    # TODO: Solution below, please remove\n",
    "    for feat1 in cat_cols[:-1]:\n",
    "        for feat2 in cat_cols[1:]:\n",
    "\n",
    "            # Create a contingency table\n",
    "            contingency_table = pd.crosstab(df[feat1], df[feat2])\n",
    "\n",
    "            # Perform the Chi-Square test\n",
    "            chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "            \n",
    "            print(f\"{feat1} {feat2} Chi-Square value: {chi2} P-value: {p_value}\")\n",
    "\n",
    "\n",
    "# Do not change this code\n",
    "calc_corr_cat(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 7.c\n",
    "# Check if pair of categorical - numeric features are correlated\n",
    "# Since all features \n",
    "\n",
    "def calc_corr_cat_num(df: pd.DataFrame) -> None:\n",
    "    '''\n",
    "    Complete the function to calculate all pairwise correlation\n",
    "    From the output Identify the pair of features that are highly correlated.\n",
    "    '''\n",
    "    \n",
    "    # TODO: Solution below, please remove\n",
    "    for feat1 in num_cols:\n",
    "        for feat2 in cat_cols:\n",
    "            groups = df.groupby(feat2)[feat1].apply(list)\n",
    "            f_statistic, p_value = f_oneway(*groups)\n",
    "\n",
    "            print(feat1, feat2, f_statistic, p_value)\n",
    "\n",
    "\n",
    "# Do not change this code\n",
    "calc_corr_cat_num(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 8.a\n",
    "# Check which of the feature are predictive (i.e. will a donor donate blood)\n",
    "# For this you can used a specific statistical test called 'Welch's t-test'\n",
    "# Which of the feature are not predictive assuming significance alpha = 0.01\n",
    "\n",
    "# Ask ChatGPT:  What is welch's t-test, and t-test - how does it help determing important features.\n",
    "\n",
    "def run_student_ttest(df, col) -> tuple[str, float]:\n",
    "    '''\n",
    "    Write a function to return p-values from the Welch's t-test\n",
    "    for feature passed into the function\n",
    "    '''\n",
    "\n",
    "    # TODO: Solution below, please remove\n",
    "    t_stat, p_val = stats.ttest_ind(df[df[label]==0][col], df[df[label]==1][col], \n",
    "                                        equal_var=False)  # Welch's t-test\n",
    "    \n",
    "    print(col, t_stat, p_val)\n",
    "\n",
    "for feat in num_cols:\n",
    "    run_student_ttest(train_df, feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 8.b\n",
    "# Check which of the feature are predictive (i.e. will a donor donate blood)\n",
    "# For this you can used a specific statistical test called 'Chi-sqaure test'\n",
    "# Which of the feature are not predictive assuming significance alpha = 0.01\n",
    "\n",
    "def run_chi_test(df, col) -> tuple[str, float]:\n",
    "    '''\n",
    "    Write a function to return p-values from the Welch's t-test\n",
    "    for feature passed into the function\n",
    "    '''\n",
    "\n",
    "    # Create a contingency table\n",
    "    contingency_table = pd.crosstab(df[col], df[label])\n",
    "\n",
    "    # Perform the Chi-Square test\n",
    "    chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "    \n",
    "    print(f\"{col} {label} Chi-Square value: {chi2} P-value: {p_value}\")\n",
    "\n",
    "for feat in cat_cols:\n",
    "    run_chi_test(train_df, feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: PENDIND COMPLETION - FIGURE OUT FEATUERS\n",
    "\n",
    "# Task 10\n",
    "# Lets try removing irrelevant features and one of correlated feature\n",
    "\n",
    "def drop_feature(df: pd.DataFrame, cols: list) -> pd.DataFrame:\n",
    "    '''\n",
    "    Create a function to remove the columns passed to this function\n",
    "    '''\n",
    "\n",
    "    # TODO: Solution below, please remove\n",
    "    # TODO: need to complete this\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Do not change this code\n",
    "proc_df = drop_feature(train_df.copy(), cols = ['Total Volume Donated (c.c.)', 'Months since First Donation'])\n",
    "proc_df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that one of the feature is not relevant. Can you think of a way to conver that feature to one that is more likely to predict if a person will donate blood in the upcoming month (i.e. March 2007)? \n",
    "\n",
    "Hint: Think about using the feature `Number of Dontations` with the irrelevant feature to create a feature that indicates how many donation the donor makes per month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Classification Metrics\n",
    "\n",
    "The most common classification metrics are - \n",
    "* Accuraccy\n",
    "* Precision\n",
    "* Recall\n",
    "* F1-Score\n",
    "Let's Ask ChatGPT what there are - <br>\n",
    "\n",
    "\n",
    "Now having analyzed the data (from Task 1), choose the best metrics for your task. <br>\n",
    "<br>\n",
    "\n",
    "Assume you got the following information from business - \n",
    "* If you prediction someone is going to subscribe, but they dont - this is huge concern. You want to reduce such `false positives` as much as possible.\n",
    "* If you predict someone is not going to subscribe, and they do - it is ok.\n",
    "\n",
    "Knowing the above - decide which metric to use. <br>\n",
    "Irrespective of what you use evaluate performance using F1 as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 11\n",
    "# Write the function to calucate the metric you have chosen\n",
    "\n",
    "def calc_perf(y_act: list, y_pred: list) -> float:\n",
    "    '''\n",
    "    Compelete this function to calculate the metric\n",
    "    you have chosen\n",
    "    '''\n",
    "\n",
    "    # TODO: Solution below, pleas remove\n",
    "    val = precision_score(y_act, y_pred)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "Now, finally we can start training the model. When training an ML model its important to have three datasets\n",
    "* Train dataset - which you use to train the model and learn parameter\n",
    "* Validation dataset - the dataset to use to figure out which parameter are the best\n",
    "* Test dataset - the hidden dataset, that you DO NOT look at. Its only use to estimate the performance in future unseen datasets.\n",
    "\n",
    "Lets start by creating these datasets - \n",
    "1. Load the train dataset \n",
    "2. ONLY run the de-duplication function on train set (lets see what performance we get without outlier removal and feature engineering)\n",
    "3. Split train dataset 80:20 to creatin a new train dataset and validation set\n",
    "2. Load the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 12\n",
    "# Preproces the train data to create traininig and validation data\n",
    "\n",
    "\n",
    "def create_dataset(df: pd.DataFrame) -> tuple[np.array, np.array, np. array, np.array]:\n",
    "    '''\n",
    "    Remove duplicate data from train file alone (using `remove_duplicates` used earlier)\n",
    "    Encode the categorical values using 'encode_cat' function\n",
    "    Split train file data into train and valid set (keep in mind what we about imbalance learned in Task 5)\n",
    "        Hint use: train_test_split (set seed to 100), and use the `stratify` field\n",
    "        Ask ChatGPT: Why is it important to stratify when creating training and validation sets for imbalanced datasets\n",
    "    \n",
    "    Return np. arrays for train features, train labels, valid features, valid labels\n",
    "\n",
    "    '''\n",
    "\n",
    "    # TODO: Solution below, pleas remove\n",
    "    df = remove_duplicates(df)\n",
    "    df = encode_cat(df, train=True)\n",
    "\n",
    "    feats = num_cols + cat_cols\n",
    "\n",
    "    X = df[feats].values\n",
    "    y = df[label].values\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, \n",
    "                                                          stratify=y, random_state=100)\n",
    "\n",
    "    return X_train, y_train, X_valid, y_valid\n",
    "\n",
    "\n",
    "# Do not change this\n",
    "X_train, y_train, X_valid, y_valid = create_dataset(pd.read_csv(data_folder + 'train.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets build a logicstic regression model. Extract out the features and labels from train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 13\n",
    "# Train a basline Logisitc Regression model with default parameters\n",
    "\n",
    "def train_base(X_train: np.array, y_train: np.array) -> LogisticRegression:\n",
    "    '''\n",
    "    Complete this function to\n",
    "    Train a baseline LogisticRegression Model with default parameter\n",
    "    Use random_state = 100 to keep results consistent\n",
    "    '''\n",
    "\n",
    "    # TODO: Solution below, please remove\n",
    "    model = LogisticRegression(random_state=100)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Do not change this\n",
    "model = train_base(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_train)\n",
    "print(\"Train Performance\")\n",
    "print(\"Selected Metric: \", calc_perf(y_train, pred), \"F1-Score: \", f1_score(y_train, pred))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "pred = model.predict(X_valid)\n",
    "print(\"Validation Performance\")\n",
    "print(\"Selected Metric: \", calc_perf(y_valid, pred),\"F1-Score: \", f1_score(y_valid, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving baseline Model and Analyzing Design Choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 14\n",
    "# Now lets try fixing the imbalance we saw in task 5 - Does it improve performance?\n",
    "\n",
    "def rebalance_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Write a function to \n",
    "    (a) remove duplicate rows in data\n",
    "    (b) balance the number of positive and negative samples in train_data\n",
    "    Hint: Use downsampling, use random_state = 100\n",
    "\n",
    "    Return balance dataframe\n",
    "    '''\n",
    "\n",
    "\n",
    "    # TODO: Solution below, please remove\n",
    "    df = remove_duplicates(train_df)\n",
    "\n",
    "    pos_df = df[df[label] == 'yes']\n",
    "    neg_df = df[df[label] == 'no']\n",
    "\n",
    "    df = pd.concat([neg_df.sample(frac=0.4, random_state=100), pos_df])\n",
    "    return df\n",
    "\n",
    "\n",
    "# Do not change the following code\n",
    "# load teh data\n",
    "train_df = pd.read_csv(data_folder + 'train.csv')\n",
    "print(train_df.shape, train_df[label].value_counts(normalize=True))\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# balance the data\n",
    "train_df = rebalance_df(train_df)\n",
    "print(train_df.shape, train_df[label].value_counts(normalize=True))\n",
    "\n",
    "# check the performance with rebalance dataset\n",
    "print(\"\\n\\n\")\n",
    "X_train, y_train, X_valid, y_valid = create_dataset(train_df)\n",
    "model = train_base(X_train, y_train)\n",
    "print(X_train.shape)\n",
    "\n",
    "pred = model.predict(X_train)\n",
    "print(\"Train Performance\")\n",
    "print(\"Selected Metric: \", calc_perf(y_train, pred), \"F1-Score: \", f1_score(y_train, pred))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "pred = model.predict(X_valid)\n",
    "print(\"Validation Performance\")\n",
    "print(\"Selected Metric: \", calc_perf(y_valid, pred),\"F1-Score: \", f1_score(y_valid, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 15\n",
    "# Another way to combat data imbalance is comfiguring class weights in the Logistic Regression model \n",
    "\n",
    "def train_tune_model(X_train: np.array, y_train: np.array):\n",
    "    '''\n",
    "    Write the function to train a Logistic Regression model\n",
    "    and use `class_weight` parameter\n",
    "    Use random_state = 100 to keep results consistent\n",
    "    '''\n",
    "\n",
    "    # TODO: Solution below, please remove code\n",
    "    model = LogisticRegression(class_weight={0:0.25, 1:0.75 }, random_state=100)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# do no change the following code\n",
    "train_df = pd.read_csv(data_folder + 'train.csv')\n",
    "X_train, y_train, X_valid, y_valid = create_dataset(train_df)\n",
    "\n",
    "model = train_tune_model(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_train)\n",
    "print(\"Train Performance\")\n",
    "print(\"Selected Metric: \", calc_perf(y_train, pred), \"F1-Score: \", f1_score(y_train, pred))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "pred = model.predict(X_valid)\n",
    "print(\"Validation Performance\")\n",
    "print(\"Selected Metric: \", calc_perf(y_valid, pred),\"F1-Score: \", f1_score(y_valid, pred))\n",
    "\n",
    "\n",
    "# Ask ChatGPT: Why does one of the methods perform better than the other\n",
    "# Hint: It could be related to the how the feature distribution for both class overlap as seen in Task 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: PENDIND COMPLETION - FIGURE OUT FEATUERS\n",
    "\n",
    "# Task 16\n",
    "# Lets try \n",
    "# (1) dropping the irrelaevant and one of the correlated feature\n",
    "# (2) Adding the new features\n",
    "# How do all this influence performance - which feature set do you finally keep?\n",
    "\n",
    "# Do not chage this code\n",
    "train_df = pd.read_csv(data_folder + 'training_data.csv')\n",
    "train_df = rebalance_df(train_df)\n",
    "\n",
    "# ADD YOUR CODE HERE\n",
    "# Hint: use `create_nea_feature` and `drop_feature` functions mentioned before\n",
    "# TODO: Solution below, remove it\n",
    "train_df = create_new_feature(train_df)\n",
    "train_df = drop_feature(train_df, cols = ['Total Volume Donated (c.c.)'])\n",
    "\n",
    "\n",
    "# Do not change this code\n",
    "X_train, y_train, X_valid, y_valid = create_dataset(train_df)\n",
    "model = train_base(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_train)\n",
    "print(\"Train Performance\")\n",
    "print(\"Selected Metric: \", calc_perf(y_train, pred), \"F1-Score: \", f1_score(y_train, pred))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "pred = model.predict(X_valid)\n",
    "print(\"Validation Performance\")\n",
    "print(\"Selected Metric: \", calc_perf(y_valid, pred),\"F1-Score: \", f1_score(y_valid, pred))\n",
    "\n",
    "\n",
    "# Did the performance drop? If so, why? \n",
    "# When you add which feature back in is the performance coming back up?\n",
    "\n",
    "# Does it make sense that adding a feature that failed student t-test helped improve performance of Logistic Regression?\n",
    "# Ask ChatGPT why this could happen (Hint it could be related to how features work together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 17\n",
    "# Nomrmalizing features to see how it impact perforamance\n",
    "\n",
    "\n",
    "def train_tune_model(X_train: np.array, y_train: np.array, \n",
    "                     scaler):\n",
    "    '''\n",
    "    Complete this function to normalize features \n",
    "    X_train: is the train features values\n",
    "    y_train: is train labels\n",
    "    scaler: The scaler you have chosen\n",
    "\n",
    "    Bonus [Optional] Task : \n",
    "    Fine-tune the Logistic Regression Model.\n",
    "    Some of the parameters you may want to experiment with are - solver, penatly and C\n",
    "    '''\n",
    "\n",
    "    # Hint: Use StandardScaler to normalize features\n",
    "    # Ask ChatGPT what type of feature scaling is best for Logistic Regression and why\n",
    "\n",
    "    # TODO: Solution below, remove this code\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    return (model, scaler)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Do not change this code\n",
    "train_df = pd.read_csv(data_folder + \"train.csv\")\n",
    "train_df = rebalance_df(train_df)\n",
    "# train_df = drop_feature(train_df, cols = ['Total Volume Donated (c.c.)'])\n",
    "\n",
    "X_train, y_train, X_valid, y_valid = create_dataset(train_df)\n",
    "model, scaler = train_tune_model(X_train, y_train, scaler)\n",
    "\n",
    "X_valid = scaler.transform(X_valid) # we use the same scaler you have used earlier\n",
    "pred = model.predict(X_valid)\n",
    "print(\"Validation Performance\")\n",
    "print(\"Selected Metric: \", calc_perf(y_valid, pred),\"F1-Score: \", f1_score(y_valid, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 18\n",
    "# Understand the coefficient from the Logistic Regression model\n",
    "\n",
    "def get_model_coeff(model : LogisticRegression, feats: list):\n",
    "    '''\n",
    "    Complete this function to print pair of values\n",
    "    (feature name, coeff value)\n",
    "    '''\n",
    "\n",
    "    # TODO: Remove this code\n",
    "    coeffs = list(model.coef_)[0]\n",
    "    print(coeffs)\n",
    "\n",
    "    for i in range(len(feats)):\n",
    "        print(feats[i], coeffs[i])\n",
    "    \n",
    "    print(\"Intercept\", model.intercept_)\n",
    "\n",
    "\n",
    "get_model_coeff(model, num_cols + cat_cols)\n",
    "\n",
    "# Ask ChatGPT: How do you interpret coeffcient of a Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 19\n",
    "# Finally apply all the transformation you deem best and get prediction on test datasets\n",
    "\n",
    "test_data = pd.read_csv(data_folder + 'test_data.csv')\n",
    "\n",
    "# TODO: Build Pipeline for test data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
