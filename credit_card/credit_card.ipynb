{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit Card Fraud Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Loading the Data\n",
    "In this task, you will load the provided credit card fraud dataset into a DataFrame. This is the first step in any machine learning workflow, where you need to ensure that the dataset is correctly imported and ready for analysis.\n",
    "\n",
    "The dataset is in CSV format, and you need to use the appropriate Python libraries to load it into a DataFrame. You should also explore the initial structure of the dataset by displaying the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "   Transaction_Amount  Transaction_Time  Merchant_ID  Card_Balance  \\\n",
      "0          124.835708         11.625301    86.583402     58.986524   \n",
      "1           93.086785          3.261624   174.054308     31.517630   \n",
      "2          132.384427          2.235485   485.080780     51.674163   \n",
      "3          176.151493          2.970619   390.613135     36.068555   \n",
      "4           88.292331         26.230675   142.012825     29.165892   \n",
      "\n",
      "   Transaction_Type  Transaction_Method  Fraud  \n",
      "0                 1                   0      0  \n",
      "1                 4                   1      0  \n",
      "2                 4                   2      0  \n",
      "3                 1                   2      0  \n",
      "4                 1                   0      0  \n",
      "\n",
      "General information about the dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Transaction_Amount  10000 non-null  float64\n",
      " 1   Transaction_Time    10000 non-null  float64\n",
      " 2   Merchant_ID         9000 non-null   float64\n",
      " 3   Card_Balance        10000 non-null  float64\n",
      " 4   Transaction_Type    10000 non-null  int64  \n",
      " 5   Transaction_Method  10000 non-null  int64  \n",
      " 6   Fraud               10000 non-null  int64  \n",
      "dtypes: float64(4), int64(3)\n",
      "memory usage: 547.0 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'credit_card_fraud_dataset_updated.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(data.head())\n",
    "\n",
    "# Get the general info about the dataset\n",
    "print(\"\\nGeneral information about the dataset:\")\n",
    "print(data.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Splitting the Data into Train and Test\n",
    "In this task, you will split the dataset into training and testing sets. The training set will be used to build the machine learning model, while the testing set will be used to evaluate its performance. A typical split ratio is 80% for training and 20% for testing, but you can experiment with other ratios as needed.\n",
    "\n",
    "It is important to perform the split randomly to avoid bias in the model's performance. Also, ensure that the split is done in a way that the class distribution (fraud and non-fraud) is maintained in both training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training set (X_train, y_train): (8000, 6) (8000,)\n",
      "Shape of the testing set (X_test, y_test): (2000, 6) (2000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(columns=['Fraud'])  # Features\n",
    "y = data['Fraud']  # Target variable\n",
    "\n",
    "# Split the data into train and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Check the shape of the resulting datasets\n",
    "print(\"Shape of the training set (X_train, y_train):\", X_train.shape, y_train.shape)\n",
    "print(\"Shape of the testing set (X_test, y_test):\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Checking the Quality of Train Data (Missing Values, Outliers, Imbalance)\n",
    "\n",
    "### Sub-task (a): Handling Missing Values\n",
    "In this sub-task, you will focus on handling missing values in the dataset. Missing data can occur in different ways, and for this task, you will fill in the missing values in the categorical features (Transaction_Type and Transaction_Method) using mode imputation, and for numerical features, you will use mean imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in the training data:\n",
      "Transaction_Amount      0\n",
      "Transaction_Time        0\n",
      "Merchant_ID           785\n",
      "Card_Balance            0\n",
      "Transaction_Type        0\n",
      "Transaction_Method      0\n",
      "dtype: int64\n",
      "\n",
      "Missing values after imputation:\n",
      "Transaction_Amount      0\n",
      "Transaction_Time        0\n",
      "Merchant_ID           785\n",
      "Card_Balance            0\n",
      "Transaction_Type        0\n",
      "Transaction_Method      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 1. Check for missing values in the training data\n",
    "print(\"Missing values in the training data:\")\n",
    "print(X_train.isnull().sum())\n",
    "\n",
    "# 2. Handle missing values in categorical features (impute with mode)\n",
    "categorical_columns = ['Transaction_Type', 'Transaction_Method']\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "X_train[categorical_columns] = cat_imputer.fit_transform(X_train[categorical_columns])\n",
    "\n",
    "# 3. Handle missing values in numerical features (impute with mean)\n",
    "numerical_columns = ['Transaction_Amount', 'Transaction_Time', 'Card_Balance']\n",
    "num_imputer = SimpleImputer(strategy='mean')\n",
    "X_train[numerical_columns] = num_imputer.fit_transform(X_train[numerical_columns])\n",
    "\n",
    "# Verify that there are no more missing values\n",
    "print(\"\\nMissing values after imputation:\")\n",
    "print(X_train.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub-task (b): Handling Outliers\n",
    "\n",
    "In this sub-task, you will focus on handling outliers in the numerical features. Outliers can skew model performance, so it's important to address them. You will resolve outliers by clipping values that fall outside a specified range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data after handling outliers:\n",
      "       Transaction_Amount  Transaction_Time  Card_Balance\n",
      "count         8000.000000       8000.000000   8000.000000\n",
      "mean           106.605542         29.590670     49.878737\n",
      "std             58.412112         26.011732     15.070003\n",
      "min            -39.497426          0.001444      8.046668\n",
      "25%             67.925854          9.052395     39.362634\n",
      "50%            103.089080         21.528801     49.967581\n",
      "75%            139.541374         43.087049     60.239944\n",
      "max            246.964653         94.139031     91.555909\n"
     ]
    }
   ],
   "source": [
    "# 1. Identifying and resolving outliers using IQR method\n",
    "for col in numerical_columns:\n",
    "    Q1 = X_train[col].quantile(0.25)\n",
    "    Q3 = X_train[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Clip outliers to the lower and upper bounds\n",
    "    X_train[col] = np.clip(X_train[col], lower_bound, upper_bound)\n",
    "\n",
    "# Check the data after outlier handling\n",
    "print(\"\\nData after handling outliers:\")\n",
    "print(X_train[numerical_columns].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub-task (c): Handling Class Imbalance\n",
    "In this sub-task, you will address the issue of class imbalance in the target variable (Fraud). A common solution for handling imbalanced datasets is to use sampling techniques to either undersample the majority class or oversample the minority class. For this task, you will use undersampling to balance the classes by randomly sampling the majority class to match the number of minority class instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution before balancing:\n",
      "Fraud\n",
      "0    7859\n",
      "1     141\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "positional indexers are out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/ads/lib/python3.9/site-packages/pandas/core/indexing.py:1676\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1675\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1678\u001b[0m     \u001b[38;5;66;03m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ads/lib/python3.9/site-packages/pandas/core/generic.py:4088\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   4079\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4080\u001b[0m \u001b[38;5;124;03mInternal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[1;32m   4081\u001b[0m \u001b[38;5;124;03mattribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4086\u001b[0m \u001b[38;5;124;03mSee the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m   4087\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 4088\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4089\u001b[0m \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ads/lib/python3.9/site-packages/pandas/core/generic.py:4068\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[0;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[1;32m   4064\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[1;32m   4065\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[1;32m   4066\u001b[0m     )\n\u001b[0;32m-> 4068\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4070\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4072\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   4074\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4075\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ads/lib/python3.9/site-packages/pandas/core/internals/managers.py:874\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[0;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[1;32m    873\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[axis]\n\u001b[0;32m--> 874\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_convert_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ads/lib/python3.9/site-packages/pandas/core/indexers/utils.py:282\u001b[0m, in \u001b[0;36mmaybe_convert_indices\u001b[0;34m(indices, n, verify)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m--> 282\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindices are out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m indices\n",
      "\u001b[0;31mIndexError\u001b[0m: indices are out-of-bounds",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Combine the minority class with the downsampled majority class\u001b[39;00m\n\u001b[1;32m     19\u001b[0m X_train_balanced \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([majority_class_downsampled, minority_class])\n\u001b[0;32m---> 20\u001b[0m y_train_balanced \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmajority_class_downsampled\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m, y_train[y_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]])\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Check the class distribution after balancing\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mClass distribution after balancing:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ads/lib/python3.9/site-packages/pandas/core/indexing.py:1153\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1150\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1152\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m-> 1153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ads/lib/python3.9/site-packages/pandas/core/indexing.py:1705\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# a list of integers\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[0;32m-> 1705\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_list_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[38;5;66;03m# a single integer\u001b[39;00m\n\u001b[1;32m   1708\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1709\u001b[0m     key \u001b[38;5;241m=\u001b[39m item_from_zerodim(key)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ads/lib/python3.9/site-packages/pandas/core/indexing.py:1679\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_take_with_is_copy(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1678\u001b[0m     \u001b[38;5;66;03m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[39;00m\n\u001b[0;32m-> 1679\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositional indexers are out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# 1. Check the class distribution in the training set\n",
    "print(\"\\nClass distribution before balancing:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "# 2. Apply undersampling to balance the classes\n",
    "# Separate the majority and minority classes\n",
    "majority_class = X_train[y_train == 0]\n",
    "minority_class = X_train[y_train == 1]\n",
    "\n",
    "# Downsample the majority class to match the minority class size\n",
    "majority_class_downsampled = resample(majority_class,\n",
    "                                      replace=False,  # without replacement\n",
    "                                      n_samples=len(minority_class),  # match minority class size\n",
    "                                      random_state=42)\n",
    "\n",
    "# Combine the minority class with the downsampled majority class\n",
    "X_train_balanced = pd.concat([majority_class_downsampled, minority_class])\n",
    "y_train_balanced = pd.concat([y_train[y_train == 0].iloc[majority_class_downsampled.index], y_train[y_train == 1]])\n",
    "\n",
    "# Check the class distribution after balancing\n",
    "print(\"\\nClass distribution after balancing:\")\n",
    "print(y_train_balanced.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Understanding the Data - Feature Value Distributions\n",
    "\n",
    "In this task, you will analyze the distributions of the features in the training data. Understanding the distribution of each feature is an important step because it can influence how you process and model the data. For example, features that are highly skewed might require transformations, and categorical features should be analyzed to understand their value counts.\n",
    "\n",
    "You will analyze both continuous features (e.g., Transaction_Amount, Transaction_Time) and categorical features (e.g., Transaction_Type, Transaction_Method).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew\n",
    "\n",
    "# 1. Visualizing the distribution of continuous features (histograms)\n",
    "continuous_columns = ['Transaction_Amount', 'Transaction_Time', 'Card_Balance']  # List of continuous features\n",
    "\n",
    "# Plot histograms for continuous features\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, col in enumerate(continuous_columns, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.histplot(X_train[col], kde=True)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Visualizing the distribution of categorical features (bar plots)\n",
    "categorical_columns = ['Transaction_Type', 'Transaction_Method']  # List of categorical features\n",
    "\n",
    "# Plot bar plots for categorical features\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, col in enumerate(categorical_columns, 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    sns.countplot(x=X_train[col])\n",
    "    plt.title(f'Count Distribution of {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Analyzing skewness of continuous features\n",
    "print(\"\\nSkewness of continuous features:\")\n",
    "for col in continuous_columns:\n",
    "    feature_skew = skew(X_train[col].dropna())\n",
    "    print(f\"{col}: Skewness = {feature_skew:.2f}\")\n",
    "\n",
    "# Suggest transformations if skewed\n",
    "print(\"\\nSuggested transformations for skewed features:\")\n",
    "for col in continuous_columns:\n",
    "    feature_skew = skew(X_train[col].dropna())\n",
    "    if feature_skew > 1:  # Positive skew\n",
    "        print(f\"{col}: Consider log transformation or scaling.\")\n",
    "    elif feature_skew < -1:  # Negative skew\n",
    "        print(f\"{col}: Consider square root transformation.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Figuring Out What Metric to Choose Best - Pros and Cons of Each\n",
    "In this task, you will learn how to choose the best evaluation metric for a binary classification problem (such as fraud detection). Different metrics provide different insights into model performance, and it’s important to select the right one based on the nature of the problem and the business objectives.\n",
    "\n",
    "In the case of fraud detection, where the goal is to correctly identify fraudulent transactions, some metrics are more appropriate than others due to the potential class imbalance (fraudulent transactions are usually much rarer than non-fraudulent ones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Create binary arrays for y_dummy1 (true labels) and y_dummy2 (predicted labels)\n",
    "y_dummy1 = np.random.choice([0, 1], size=1000)  # 1000 samples, with values 0 or 1 (fraud or not)\n",
    "y_dummy2 = np.random.choice([0, 1], size=1000)  # Predicted labels\n",
    "\n",
    "# 1. Evaluate using multiple metrics: Accuracy, Precision, Recall, F1-Score, and ROC AUC\n",
    "\n",
    "# Accuracy: Proportion of correctly classified transactions (fraud and non-fraud)\n",
    "accuracy = accuracy_score(y_dummy1, y_dummy2)\n",
    "\n",
    "# Precision: How many of the predicted fraudulent transactions were actually fraud?\n",
    "precision = precision_score(y_dummy1, y_dummy2)\n",
    "\n",
    "# Recall: How many of the actual fraudulent transactions were correctly predicted?\n",
    "recall = recall_score(y_dummy1, y_dummy2)\n",
    "\n",
    "# F1-Score: Harmonic mean of precision and recall\n",
    "f1 = f1_score(y_dummy1, y_dummy2)\n",
    "\n",
    "# ROC AUC: Measures the model’s ability to distinguish between fraud and non-fraud\n",
    "# For this, y_dummy2 should be probability scores, so assuming we have predicted probabilities, we'll simulate them\n",
    "y_dummy2_prob = np.random.rand(1000)  # Random probability scores for predictions\n",
    "roc_auc = roc_auc_score(y_dummy1, y_dummy2_prob)\n",
    "\n",
    "# Printing the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-Score: {f1}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Building a Baseline No-ML Solution\n",
    "In this task, you will build a baseline no-machine learning solution. A baseline model is crucial for comparing the performance of machine learning models. It allows you to measure how well a machine learning model is performing relative to a simple or naïve approach.\n",
    "\n",
    "For the fraud detection problem, a natural baseline approach is to predict that all transactions are non-fraudulent (i.e., predict 0 for all cases). This simple model will serve as a baseline, and you can later compare it with the performance of your logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# 1. Baseline solution: Predict 0 (non-fraudulent) for all transactions\n",
    "y_pred_baseline = [0] * len(y_test_classification)\n",
    "\n",
    "# 2. Evaluate the baseline model's performance\n",
    "accuracy_baseline = accuracy_score(y_test_classification, y_pred_baseline)\n",
    "precision_baseline = precision_score(y_test_classification, y_pred_baseline)\n",
    "recall_baseline = recall_score(y_test_classification, y_pred_baseline)\n",
    "f1_baseline = f1_score(y_test_classification, y_pred_baseline)\n",
    "roc_auc_baseline = roc_auc_score(y_test_classification, y_pred_baseline)\n",
    "\n",
    "print(f\"Baseline Accuracy: {accuracy_baseline:.4f}\")\n",
    "print(f\"Baseline Precision: {precision_baseline:.4f}\")\n",
    "print(f\"Baseline Recall: {recall_baseline:.4f}\")\n",
    "print(f\"Baseline F1-Score: {f1_baseline:.4f}\")\n",
    "print(f\"Baseline ROC AUC: {roc_auc_baseline:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Building a Basic Logistic Regression Model - Feature Transformation\n",
    "In this task, you will build a basic logistic regression model for the fraud detection problem. You will also apply necessary feature transformations to ensure that the data is properly prepared for logistic regression. These transformations will include encoding categorical variables and normalizing continuous features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Split the data into features (X) and target (y)\n",
    "X = df.drop('Fraud', axis=1)\n",
    "y = df['Fraud']\n",
    "\n",
    "# 2. Define which features are categorical and which are continuous\n",
    "categorical_features = ['Transaction_Type', 'Transaction_Method']\n",
    "continuous_features = [col for col in X.columns if col not in categorical_features]\n",
    "\n",
    "# 3. Set up a column transformer to apply appropriate transformations\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), continuous_features),  # Standardize continuous features\n",
    "        ('cat', OneHotEncoder(), categorical_features)  # One-hot encode categorical features\n",
    "    ])\n",
    "\n",
    "# 4. Create a pipeline that first applies the transformations and then fits the logistic regression model\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))  # Logistic Regression Model\n",
    "])\n",
    "\n",
    "# 5. Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 6. Train the model using the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 7. Predict using the trained model\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# 8. Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, pipeline.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8: Evaluating Performance of Model Using Chosen Metric and Comparing with No-Machine Learning Solution\n",
    "Task Description:\n",
    "In this task, you will evaluate the performance of the logistic regression model built in Task 6 using the chosen classification metrics (accuracy, precision, recall, F1-score, and ROC AUC). Additionally, you will compare the model’s performance with the baseline no-machine learning solution built in Task 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Evaluate the logistic regression model using the same metrics\n",
    "accuracy_logreg = accuracy_score(y_test, y_pred)\n",
    "precision_logreg = precision_score(y_test, y_pred)\n",
    "recall_logreg = recall_score(y_test, y_pred)\n",
    "f1_logreg = f1_score(y_test, y_pred)\n",
    "roc_auc_logreg = roc_auc_score(y_test, pipeline.predict_proba(X_test)[:, 1])\n",
    "\n",
    "# 2. Compare with the baseline model metrics\n",
    "# We already calculated baseline metrics earlier, so we'll use those:\n",
    "\n",
    "print(\"\\nEvaluation of Logistic Regression Model:\")\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_logreg:.4f}\")\n",
    "print(f\"Logistic Regression Precision: {precision_logreg:.4f}\")\n",
    "print(f\"Logistic Regression Recall: {recall_logreg:.4f}\")\n",
    "print(f\"Logistic Regression F1-Score: {f1_logreg:.4f}\")\n",
    "print(f\"Logistic Regression ROC AUC: {roc_auc_logreg:.4f}\")\n",
    "\n",
    "print(\"\\nEvaluation of Baseline Model (No-ML):\")\n",
    "print(f\"Baseline Accuracy: {accuracy_baseline:.4f}\")\n",
    "print(f\"Baseline Precision: {precision_baseline:.4f}\")\n",
    "print(f\"Baseline Recall: {recall_baseline:.4f}\")\n",
    "print(f\"Baseline F1-Score: {f1_baseline:.4f}\")\n",
    "print(f\"Baseline ROC AUC: {roc_auc_baseline:.4f}\")\n",
    "\n",
    "# 3. Interpret the results:\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"1. Accuracy can be misleading in imbalanced datasets, so check precision and recall.\")\n",
    "print(\"2. Logistic regression should perform better in terms of precision, recall, F1-score, and ROC AUC.\")\n",
    "print(\"3. Look at the ROC AUC to see how well the model distinguishes between fraud and non-fraud.\")\n",
    "print(\"4. If the logistic regression model significantly outperforms the baseline, it indicates the benefit of using machine learning.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ads",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
